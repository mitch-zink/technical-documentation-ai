# üìÑ Technical Documentation AI


[![Streamlit](https://img.shields.io/badge/-Streamlit-FF4B4B?style=flat-square&logo=streamlit&logoColor=white)](https://streamlit.io/)
[![OpenAI](https://img.shields.io/badge/-OpenAI-412991?style=flat-square&logo=openai&logoColor=white)](https://openai.com/)
[![Langchain](https://img.shields.io/badge/-Langchain-gray?style=flat-square)](https://www.langchain.com/)

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://technical-documentation-ai-g-efxnappvkcu9kyyaksqvpwl.streamlit.app/)

## ‚ú® Description
The AI chatbot can answer technical questions in real time by checking documentation for AWS, GitHub, Fivetran, Looker, dbt, Prefect, & Snowflake.

## üôã‚Äç‚ôÇÔ∏è Sample Q&A
![example](example.png)

## üôã‚Äç‚ôÇÔ∏è User Question Processing Workflow

To effectively handle a user‚Äôs question, the system performs the following steps:

1. **Query Generation**: Utilize a Large Language Model (LLM) to generate a comprehensive set of queries based on the provided user input.
2. **Search Execution**: Conduct searches for each of the generated queries.
3. **URL Storage**: Collect and store the URLs obtained from the search results in `self.urls`.
4. **URL Check**: Identify any URLs that are new and have not been processed previously, ensuring they do not exist in `self.url_database`.
5. **Content Transformation and Storage**: Load, transform, and add these new URLs exclusively to the vectorstore.
6. **Relevant Document Retrieval**: Query the vectorstore for documents that are relevant to the questions generated by the LLM.
7. **Final Result Preparation**: Ensure that only unique documents are selected, compiling them to form the final result set.

## üîß Configuration
You only need to supply a few things.

In `settings()` function, supply:

* Search: Select the search tool you want to use (e.g., GoogleSearchAPIWrapper). 
* Vectorstore: Select the vectorstore and embeddings you want to use (e.g., Chroma, OpenAIEmbeddings).
* Select the LLM you want to use (e.g., ChatOpenAI).

To use `st.secrets` set enviorment variables in `.streamlit/secrets.toml` file.
 
Or, simply add environemnt variables and remove `st.secrets`: 
```
import os
os.environ["GOOGLE_API_KEY"] = "YOUR_API_KEY"
os.environ["GOOGLE_CSE_ID"] = "YOUR_CSE_ID" 
os.environ["OPENAI_API_BASE"] = "https://api.openai.com/v1"
os.environ["OPENAI_API_KEY"] = "YOUR_API_KEY"

```

### üõ†Ô∏è API Key Configuration

- **`GOOGLE_API_KEY`**: Obtainable from [Google Cloud Console](https://console.cloud.google.com/apis/api/customsearch.googleapis.com/credentials).
  
- **`GOOGLE_CSE_ID`**: Accessible at [Google Programmable Search Engine](https://programmablesearchengine.google.com/), requiring site configuration.
  ![Configuration Example](example_2.png)
  
- **`OPENAI_API_KEY`**: Retrieve from [OpenAI API Keys](https://beta.openai.com/account/api-keys).

## üë∑ Setup & Run for MacOS
```
python3.9 -m venv venv && source venv/bin/activate && pip3 install --upgrade pip && pip3 install -r requirements.txt && streamlit run technical-documentation-ai.py
```

## üë∑‚Äç‚ôÄÔ∏è Setup & Run for Windows
```
python3.9 -m venv venv && .\venv\Scripts\activate && python -m pip install --upgrade pip && pip install -r requirements.txt && streamlit run technical-documentation-ai.py
```